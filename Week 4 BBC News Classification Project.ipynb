{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4 Peer Review Project:  Kaggle Competition: BBC News Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Part 1:\n",
    "\n",
    "For this week’s mini-project, you will participate in this Kaggle competition:  \n",
    "\n",
    "Kaggle Competition: BBC News Classification \n",
    " [80 pts]\n",
    "\n",
    "This Kaggle competition is about categorizing news articles. You will use matrix factorization to predict the category and submit your notebook for peer evaluation. \n",
    "\n",
    "The part has 80 points. The instructions summarize the criteria you will use to guide your submission and review others’ submissions. \n",
    "\n",
    "You will submit one deliverable for Part 1: \n",
    "\n",
    "A Jupyter notebook with exploratory data analysis (EDA) procedure, model building and training, and comparison with supervised learning. \n",
    "\n",
    "Suppose your work becomes so large that it doesn’t fit into one notebook (or you think it will be less readable by having one large notebook). In that case, you can make several notebooks or scripts in a GitHub repository (as deliverable 3) and submit a report-style notebook or pdf instead.\n",
    "\n",
    "##### Part 2:\n",
    "\n",
    "Limitation(s) of sklearn’s non-negative matrix factorization library. [20 pts]\n",
    "\n",
    "1. Load the movie ratings data (as in the HW3-recommender-system) and use matrix factorization technique(s) and predict the missing ratings from the test data. Measure the RMSE. You should use sklearn library. [10 pts]\n",
    "\n",
    "\n",
    "2. Discuss the results and why sklearn's non-negative matrix facorization library did not work well compared to simple baseline or similarity-based methods we’ve done in Module 3. Can you suggest a way(s) to fix it? [10 pts]\n",
    "\n",
    "\n",
    "references:\n",
    "\n",
    "https://medium.com/logicai/non-negative-matrix-factorization-for-recommendation-systems-985ca8d5c16c\n",
    "\n",
    "https://pub.towardsai.net/topic-modeling-with-nmf-for-user-reviews-classification-65913d0b44fe\n",
    "\n",
    "https://chat.openai.com/share/532e586a-1268-4bae-aaf1-3182426380d2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from numba import jit\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. \n",
    "\n",
    "#### Instructions:  Step 1\n",
    "Extracting word features and show Exploratory Data Analysis (EDA) — Inspect, Visualize and Clean the Data (15 pts)\n",
    "\n",
    "Show a few visualizations like histograms. Describe any data cleaning procedures. Based on your EDA, what is your plan of analysis? \n",
    "\n",
    "Please feel free to look at online resources on processing raw texts to feature vectors. Many methods process texts to matrix form (word embedding), including TF-IDF, GloVe, Word2Vec, etc. Pick a method and process the raw texts to word embedding. Briefly explain the method(s) and how they work in your own words. Also, do exploratory data analysis such as word statistics and/or visualization.\n",
    "\n",
    "As we did not learn natural language processing (NLP) specific techniques such as word embeddings in the lectures, we recommend reading discussions and example codes from others in the Kaggle and/or doing some research online to make sure you understand. You can refer to any resource as needed, but make sure you “demonstrate” your understanding- please include explaining in your own words, discussions, and your interpretation. Also importantly, please have a reference list at the end of the report. \n",
    "\n",
    "\n",
    "##### Read Files and perform initial visual inspection of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/ayeshamendoza/UCB/5510 - Unsupervised Learning/data'\n",
    "\n",
    "files = glob.glob(os.path.join(path, \"*.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/ayeshamendoza/UCB/5510 - Unsupervised Learning/data/BBC News Train.csv',\n",
       " '/Users/ayeshamendoza/UCB/5510 - Unsupervised Learning/data/BBC News Test.csv',\n",
       " '/Users/ayeshamendoza/UCB/5510 - Unsupervised Learning/data/BBC News Sample Solution.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure all our rows are labeled.  It looks like all our training data are set to one of the 5 categories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleId    0\n",
       "Text         0\n",
       "Category     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls in the dataframe\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1833</td>\n",
       "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>154</td>\n",
       "      <td>german business confidence slides german busin...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1101</td>\n",
       "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1976</td>\n",
       "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>917</td>\n",
       "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text  Category\n",
       "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
       "1        154  german business confidence slides german busin...  business\n",
       "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
       "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
       "4        917  enron bosses in $168m payout eighteen former e...  business"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ArticleId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1018</td>\n",
       "      <td>qpr keeper day heads for preston queens park r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1319</td>\n",
       "      <td>software watching while you work software that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1138</td>\n",
       "      <td>d arcy injury adds to ireland woe gordon d arc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>459</td>\n",
       "      <td>india s reliance family feud heats up the ongo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020</td>\n",
       "      <td>boro suffer morrison injury blow middlesbrough...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ArticleId                                               Text\n",
       "0       1018  qpr keeper day heads for preston queens park r...\n",
       "1       1319  software watching while you work software that...\n",
       "2       1138  d arcy injury adds to ireland woe gordon d arc...\n",
       "3        459  india s reliance family feud heats up the ongo...\n",
       "4       1020  boro suffer morrison injury blow middlesbrough..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(files[1])\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation\n",
    "\n",
    "##### The following validations were done:\n",
    "- vaidate that article is assigned to one or more category to determine if it is a multi-class classification or a multi-label classification.\n",
    "\n",
    "- Inspect the number of rows for each category to determine if we have imbalanced data, so we can handle if needed.\n",
    "- Inspect for missing or null values, to make sure every article in Training dataset has a label, and that the `Text` column is not nulls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if an article is assigned to more than one category\n",
    "- It looks good, all articles are just assigned to one category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_counts = train_df['ArticleId'].value_counts()\n",
    "\n",
    "# Check for multiple rows for an ArticleID\n",
    "duplicate_article_ids = article_counts[article_counts > 1].index\n",
    "duplicate_article_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleId    0\n",
       "Text         0\n",
       "Category     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Inspect how many rows we have for each category, and determine if we have imbalanced data.\n",
    "\n",
    "It looks like we have pretty good distribution of samples for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: ArticleId, dtype: int64)\n",
      "Empty DataFrame\n",
      "Columns: [ArticleId, Text, Category]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "article_counts = train_df['ArticleId'].value_counts()\n",
    "\n",
    "# Filter to find ArticleIds with more than one occurrence\n",
    "more_than_one = article_counts[article_counts > 1]\n",
    "\n",
    "# Show the ArticleIds that have more than one occurrence\n",
    "print(more_than_one)\n",
    "\n",
    "repeated_articles = train_df[train_df['ArticleId'].isin(more_than_one.index)]\n",
    "print(repeated_articles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View Distribution of data to verify if we have an imbalanced dataset.\n",
    "\n",
    "- The different categories seems to be well distributed, no class has a significantly low number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: xlabel='Category', ylabel='count'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Category', data=train_df, color='dodgerblue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text data Pre-processing\n",
    "\n",
    "The following pre-processing steps were done with the text data:\n",
    "- Tokenization: breaks the down the text into tokens\n",
    "- Stemming, Lemmatization: removes redundancy in words by finding the root form by removing affixes from inflected word forms\n",
    "- Remove punctuation, numbers and stopwords: stopwords are the most common words in the language but are not important in deriving the meaning, these are words such as 'a', 'but', they', etc.  Stop words can be customizable depending on the industry you are working on, i.e. if you are working for a bank, the word 'bank' might appear frequently in the documents and might not be relevant in analyzing documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worldcom', 'ex-boss', 'launches', 'defence', 'lawyers', 'defending', 'former', 'worldcom', 'chief', 'bernie', 'ebbers', 'against', 'a', 'battery', 'of', 'fraud', 'charges', 'have', 'called', 'a', 'company', 'whistleblower', 'as', 'their', 'first', 'witness', '.', 'cynthia', 'cooper', 'worldcom', 's', 'ex-head', 'of', 'internal', 'accounting', 'alerted', 'directors', 'to', 'irregular', 'accounting', 'practices', 'at', 'the', 'us', 'telecoms', 'giant', 'in', '2002.', 'her', 'warnings', 'led', 'to', 'the', 'collapse', 'of', 'the', 'firm', 'following', 'the', 'discovery', 'of', 'an', '$', '11bn', '(', '£5.7bn', ')', 'accounting', 'fraud', '.', 'mr', 'ebbers', 'has', 'pleaded', 'not', 'guilty', 'to', 'charges', 'of', 'fraud', 'and', 'conspiracy', '.', 'prosecution', 'lawyers', 'have', 'argued', 'that', 'mr', 'ebbers', 'orchestrated', 'a', 'series', 'of', 'accounting', 'tricks', 'at', 'worldcom', 'ordering', 'employees', 'to', 'hide', 'expenses', 'and', 'inflate', 'revenues', 'to', 'meet', 'wall', 'street', 'earnings', 'estimates', '.', 'but', 'ms', 'cooper', 'who', 'now', 'runs', 'her', 'own', 'consulting', 'business', 'told', 'a', 'jury', 'in', 'new', 'york', 'on', 'wednesday', 'that', 'external', 'auditors', 'arthur', 'andersen', 'had', 'approved', 'worldcom', 's', 'accounting', 'in', 'early', '2001', 'and', '2002.', 'she', 'said', 'andersen', 'had', 'given', 'a', 'green', 'light', 'to', 'the', 'procedures', 'and', 'practices', 'used', 'by', 'worldcom', '.', 'mr', 'ebber', 's', 'lawyers', 'have', 'said', 'he', 'was', 'unaware', 'of', 'the', 'fraud', 'arguing', 'that', 'auditors', 'did', 'not', 'alert', 'him', 'to', 'any', 'problems', '.', 'ms', 'cooper', 'also', 'said', 'that', 'during', 'shareholder', 'meetings', 'mr', 'ebbers', 'often', 'passed', 'over', 'technical', 'questions', 'to', 'the', 'company', 's', 'finance', 'chief', 'giving', 'only', 'brief', 'answers', 'himself', '.', 'the', 'prosecution', 's', 'star', 'witness', 'former', 'worldcom', 'financial', 'chief', 'scott', 'sullivan', 'has', 'said', 'that', 'mr', 'ebbers', 'ordered', 'accounting', 'adjustments', 'at', 'the', 'firm', 'telling', 'him', 'to', 'hit', 'our', 'books', '.', 'however', 'ms', 'cooper', 'said', 'mr', 'sullivan', 'had', 'not', 'mentioned', 'anything', 'uncomfortable', 'about', 'worldcom', 's', 'accounting', 'during', 'a', '2001', 'audit', 'committee', 'meeting', '.', 'mr', 'ebbers', 'could', 'face', 'a', 'jail', 'sentence', 'of', '85', 'years', 'if', 'convicted', 'of', 'all', 'the', 'charges', 'he', 'is', 'facing', '.', 'worldcom', 'emerged', 'from', 'bankruptcy', 'protection', 'in', '2004', 'and', 'is', 'now', 'known', 'as', 'mci', '.', 'last', 'week', 'mci', 'agreed', 'to', 'a', 'buyout', 'by', 'verizon', 'communications', 'in', 'a', 'deal', 'valued', 'at', '$', '6.75bn', '.'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing tokenization on sample Text\n",
    "\n",
    "# tokenize and print tokens from the sample Text\n",
    "sample_tokens = nltk.word_tokenize(train_df.iloc[0]['Text'])\n",
    "print(sample_tokens,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set-up Stemmer, translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = str.maketrans(string.punctuation, ' '*32)\n",
    "porterStemmer = PorterStemmer()\n",
    "\n",
    "# get list of lemmatized/stemmed tokens\n",
    "def stemTokenList(tokens, stemmer):\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "# get out stemmed tokens from text\n",
    "def noPunctWordTokenizerStemmer(text, stemmer=porterStemmer):\n",
    "    # basic tokens to feed to our stem tokenizer\n",
    "    tokens = nltk.word_tokenize(text.translate(translator))\n",
    "    # stem\n",
    "    stemmed_tokens = stemTokenList(tokens, stemmer)\n",
    "    return stemmed_tokens\n",
    "\n",
    "def cleanText(text, stemmer=porterStemmer):\n",
    "    # basic tokens to feed to our stem tokenizer\n",
    "    stopwords_english = stopwords.words('english')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text.translate(translator))\n",
    "    \n",
    "    filtered_tokens = [token for token in tokens if not token.isdigit()]\n",
    "    filtered_tokens = [token for token in filtered_tokens if token not in stopwords_english]\n",
    "    \n",
    "    # stem\n",
    "    stemmed_tokens = stemTokenList(filtered_tokens, stemmer)\n",
    "    text = ' '.join(stemmed_tokens)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned tokens\n",
    "train_df['cleaned_tokens'] = train_df['Text'].apply(lambda x: cleanText(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count_dict = {}\n",
    "\n",
    "for ix, row in train_df.iterrows():\n",
    "    for word in row['cleaned_tokens'].split(\" \"):\n",
    "        if word in word_count_dict:\n",
    "            word_count_dict[word] += 1\n",
    "        else:\n",
    "            word_count_dict[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_dict = dict(sorted(word_count_dict.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: title={'center': 'Top 20 most frequent words used'}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Top 20 most frequent words used\")\n",
    "sns.barplot(x=list(sorted_dict.keys())[:20], y=list(sorted_dict.values())[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction:\n",
    "\n",
    "For feature processing, I used TF-IDF for this iteration.\n",
    "\n",
    "`TF-IDF` is a technique that assesses the importance of words relative to a collection of documents\n",
    "\n",
    "`TF`: is the frequency of any term in the document\n",
    "\n",
    "`IDF`: accounts for the ratio of the documents that include that specific 'term'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df['cleaned_tokens'],\n",
    "                                                    train_df['Category'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF matrix of 1192 articles with 15285 feature tokens\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "\n",
    "# create the transformer\n",
    "\n",
    "tfidf = TfidfVectorizer(use_idf=True, smooth_idf=True, sublinear_tf=True)\n",
    "\n",
    "# features_tfidf = tfidf.fit_transform(features_counts) # For transformer\n",
    "features_tfidf = tfidf.fit_transform(X_train.values)\n",
    "\n",
    "print(\"TF-IDF matrix of %d articles with %d feature tokens\" % features_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NMF using tf-idf features\n",
    "beta_loss_params = {'frobenius':'cd', 'kullback-leibler':'mu'}\n",
    "l1_ratio_params = [0.0, 1.0]\n",
    "\n",
    "# Initialize nmf_score dict to keep track of train scores for nmf\n",
    "nmf_score = {}\n",
    "# num_categories were set to 5 since there are 5 categories to classify\n",
    "num_categories = 5\n",
    "random_state = 42\n",
    "\n",
    "\n",
    "for loss_param, solver in beta_loss_params.items():\n",
    "    nmfs = []\n",
    "    for l1_param in l1_ratio_params:\n",
    "        param_dict = {}\n",
    "        nmf = NMF(n_components=num_categories,\n",
    "                  random_state=random_state,\n",
    "                  solver=solver,\n",
    "                  beta_loss=loss_param,\n",
    "                  l1_ratio = l1_param)\n",
    "        nmf.fit(features_tfidf)\n",
    "        param_dict['l1'] = l1_param\n",
    "        param_dict['nmf_fit'] = nmf\n",
    "        nmfs.append(param_dict)\n",
    "        \n",
    "    nmf_score[loss_param] = nmfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'frobenius': [{'l1': 0.0, 'nmf_fit': NMF(n_components=5, random_state=42)},\n",
       "  {'l1': 1.0, 'nmf_fit': NMF(l1_ratio=1.0, n_components=5, random_state=42)}],\n",
       " 'kullback-leibler': [{'l1': 0.0,\n",
       "   'nmf_fit': NMF(beta_loss='kullback-leibler', n_components=5, random_state=42, solver='mu')},\n",
       "  {'l1': 1.0,\n",
       "   'nmf_fit': NMF(beta_loss='kullback-leibler', l1_ratio=1.0, n_components=5, random_state=42,\n",
       "       solver='mu')}]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display top `n` words for the different categories identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " frobenius , 0.0 \n",
      "Topic 0 : elect mr labour blair parti tori govern minist would prime said say leader plan tax\n",
      "Topic 1 : game play win england match player team cup first final side champion back injuri coach\n",
      "Topic 2 : use peopl mobil phone technolog user servic comput digit softwar net music said onlin video\n",
      "Topic 3 : film award star best actor oscar nomin actress director comedi music aviat includ ceremoni year\n",
      "Topic 4 : growth market economi said bank compani firm year econom us share rate sale price rise\n",
      "\n",
      " frobenius , 1.0 \n",
      "Topic 0 : elect mr labour blair parti tori govern minist would prime said say leader plan tax\n",
      "Topic 1 : game play win england match player team cup first final side champion back injuri coach\n",
      "Topic 2 : use peopl mobil phone technolog user servic comput digit softwar net music said onlin video\n",
      "Topic 3 : film award star best actor oscar nomin actress director comedi music aviat includ ceremoni year\n",
      "Topic 4 : growth market economi said bank compani firm year econom us share rate sale price rise\n",
      "\n",
      " kullback-leibler , 0.0 \n",
      "Topic 0 : said mr would say could govern told next time elect need plan minist new peopl\n",
      "Topic 1 : play game win player match first final england champion year team cup season injuri coach\n",
      "Topic 2 : use technolog mobil phone user comput peopl softwar servic consum digit net internet onlin firm\n",
      "Topic 3 : film star award music best actor show oscar nomin singer band includ tv album song\n",
      "Topic 4 : compani market firm bank growth share year sale economi us dollar profit econom said price\n",
      "\n",
      " kullback-leibler , 1.0 \n",
      "Topic 0 : said mr would say could govern told next time elect need plan minist new peopl\n",
      "Topic 1 : play game win player match first final england champion year team cup season injuri coach\n",
      "Topic 2 : use technolog mobil phone user comput peopl softwar servic consum digit net internet onlin firm\n",
      "Topic 3 : film star award music best actor show oscar nomin singer band includ tv album song\n",
      "Topic 4 : compani market firm bank growth share year sale economi us dollar profit econom said price\n"
     ]
    }
   ],
   "source": [
    "def display_top_words(feature_names, nmf, n_top_words=15):\n",
    "    topic_dict = {}\n",
    "    for i, topic_vec in enumerate(nmf.components_):\n",
    "        topic_words = []\n",
    "        for fid in topic_vec.argsort()[-1:-n_top_words-1:-1]:\n",
    "            topic_words.append(feature_names[fid])\n",
    "\n",
    "            \n",
    "        topic_dict[i] = topic_words\n",
    "        \n",
    "    return topic_dict\n",
    "\n",
    "for loss_param, nmfs in nmf_score.items():\n",
    "    for nmf_fitted in nmfs:\n",
    "        topics = display_top_words(tfidf.get_feature_names(), nmf_fitted['nmf_fit'], n_top_words=15)\n",
    "        print(f\"\\n {loss_param} , {nmf_fitted['l1']} \")\n",
    "        for key, topic_words in topics.items():\n",
    "            print(f\"Topic {key} : {' '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can map labels based on the following topics found by NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_num_map = {'tech':2, 'sport':1, 'politics':0, 'business':4, 'entertainment':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pd.DataFrame({'tokens': X_train.values, 'actual_labels': y_train.values})\n",
    "train_preds['actual_num_labels'] = train_preds['actual_labels'].map(label_to_num_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate and Tune NMF models\n",
    "\n",
    "- different beta_loss_params and l1_ratio were used, but as we will see in the results below that the `l1_ratio` did not contribute to any change in the scores, but for the `beta_loss` parameter, the accuracy is better with `beta_loss = 'frobenius'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Training accuracy for NMF (parameters: beta_loss_params = 'frobenius', l1_ratio = 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Training Accuracy : params = frobenius, 0.0 : 0.9404362416107382\n",
      "NMF Training Accuracy : params = frobenius, 1.0 : 0.9404362416107382\n",
      "NMF Training Accuracy : params = kullback-leibler, 0.0 : 0.9219798657718121\n",
      "NMF Training Accuracy : params = kullback-leibler, 1.0 : 0.9219798657718121\n"
     ]
    }
   ],
   "source": [
    "# Get NMF prediction for topics\n",
    "\n",
    "for loss_param, nmfs in nmf_score.items():\n",
    "    for nmf_fitted in nmfs:\n",
    "        nmf = nmf_fitted['nmf_fit']\n",
    "        train_pred = nmf.transform(features_tfidf)\n",
    "        train_preds['pred_label'] = np.argmax(train_pred, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(train_preds['actual_num_labels'], train_preds['pred_label'])\n",
    "        print(f\"NMF Training Accuracy : params = {loss_param}, {nmf_fitted['l1']} : {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = pd.DataFrame({'tokens': X_test.values, 'actual_labels': y_test.values})\n",
    "test_preds['actual_num_labels'] = test_preds['actual_labels'].map(label_to_num_map)\n",
    "\n",
    "test_tfidf = tfidf.transform(X_test.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate different NMF's using Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Test Accuracy : params = frobenius, 0.0 : 0.959731543624161\n",
      "NMF Test Accuracy : params = frobenius, 1.0 : 0.959731543624161\n",
      "NMF Test Accuracy : params = kullback-leibler, 0.0 : 0.9261744966442953\n",
      "NMF Test Accuracy : params = kullback-leibler, 1.0 : 0.9261744966442953\n"
     ]
    }
   ],
   "source": [
    "for loss_param, nmfs in nmf_score.items():\n",
    "    for nmf_fitted in nmfs:\n",
    "        \n",
    "        test_preds = pd.DataFrame({'tokens': X_test.values, 'actual_labels': y_test.values})\n",
    "        test_preds['actual_num_labels'] = test_preds['actual_labels'].map(label_to_num_map)\n",
    "        \n",
    "        nmf = nmf_fitted['nmf_fit']\n",
    "        test_pred = nmf.transform(test_tfidf)\n",
    "        test_preds['pred_label'] = np.argmax(test_pred, axis=1)\n",
    "\n",
    "        accuracy = accuracy_score(test_preds['actual_num_labels'], test_preds['pred_label'])\n",
    "        print(f\"NMF Test Accuracy : params = {loss_param}, {nmf_fitted['l1']} : {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Accuracy and Classification Report for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NMF Test set accuracy: 0.96\n",
      "NMF Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95        56\n",
      "           1       0.97      1.00      0.98        63\n",
      "           2       0.92      0.97      0.94        58\n",
      "           3       1.00      0.91      0.95        46\n",
      "           4       0.96      0.97      0.97        75\n",
      "\n",
      "    accuracy                           0.96       298\n",
      "   macro avg       0.96      0.96      0.96       298\n",
      "weighted avg       0.96      0.96      0.96       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_preds = pd.DataFrame({'tokens': X_test.values, 'actual_labels': y_test.values})\n",
    "test_preds['actual_num_labels'] = test_preds['actual_labels'].map(label_to_num_map)\n",
    "\n",
    "nmf = nmf_score['frobenius'][0]['nmf_fit']\n",
    "test_pred = nmf.transform(test_tfidf)\n",
    "test_preds['pred_label'] = np.argmax(test_pred, axis=1)\n",
    "print(\"NMF Test set accuracy: {:.2f}\".format(accuracy_score(test_preds['actual_num_labels'] , test_preds['pred_label'])))\n",
    "print(\"NMF Classification report:\\n\", classification_report(test_preds['actual_num_labels'] , test_preds['pred_label']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3. Compare with supervised learning [30 pts]\n",
    "\n",
    "Use the following steps to guide your work:\n",
    "\n",
    "1) Pick and train a supervised learning method(s) and compare the results (train and test performance)\n",
    "2) Discuss comparison with the unsupervised approach. You may try changing the train data size (e.g., Include only 10%, 20%, 50% of labels, and observe train/test performance changes). Which methods are data-efficient (require a smaller amount of data to achieve similar results)? What about overfitting?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   15.9s\n",
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   24.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Best parameters found:  {'clf__C': 10, 'tfidf__max_df': 1.0, 'tfidf__min_df': 1}\n",
      "LR Best cross-validation score: 0.97\n",
      "LR Test set accuracy: 0.97\n",
      "LR Classification report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "     business       0.96      0.99      0.97        75\n",
      "entertainment       0.96      1.00      0.98        46\n",
      "     politics       0.96      0.93      0.95        56\n",
      "        sport       0.98      1.00      0.99        63\n",
      "         tech       1.00      0.95      0.97        58\n",
      "\n",
      "     accuracy                           0.97       298\n",
      "    macro avg       0.97      0.97      0.97       298\n",
      " weighted avg       0.97      0.97      0.97       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('clf', LogisticRegression(max_iter=200, random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_lr = {\n",
    "    'tfidf__max_df': [0.75, 1.0],\n",
    "    'tfidf__min_df': [1, 2],\n",
    "    'clf__C': [0.1, 1, 10]\n",
    "}\n",
    "\n",
    "grid_search_lr = GridSearchCV(pipeline_lr, param_grid_lr, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search_lr.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters and best score for Logistic Regression\n",
    "print(\"LR Best parameters found: \", grid_search_lr.best_params_)\n",
    "print(\"LR Best cross-validation score: {:.2f}\".format(grid_search_lr.best_score_))\n",
    "\n",
    "# Predict on the test set with Logistic Regression\n",
    "y_pred_lr = grid_search_lr.predict(X_test)\n",
    "\n",
    "# Evaluate the Logistic Regression model\n",
    "print(\"LR Test set accuracy: {:.2f}\".format(accuracy_score(y_test, y_pred_lr)))\n",
    "print(\"LR Classification report:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Summary:\n",
    "\n",
    "- After running the BBC News Classification dataset using NMF (Unsupervised technique), and using Logistic Regression for Supervised technique, the Supervised ML technique outperformed the NMF by .01.\n",
    "Both models appear to perform well and generalized well with the test data -- no overfitting observed from the results yielded.\n",
    "\n",
    "- NMF does the classification/grouping by uncovering hidden patterns/structure in the data, which appears to be in this case comparable to Logistic Regression which was used for the Supervised ML approach.  Logistic Regression / Supervised ML could provide more accurate results since Supervised ML models are trained to learn from the data. \n",
    "\n",
    "Additional tuning and cross-validation can be done using NMF, but due to time constraints, I am reporting the results generated from this iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
